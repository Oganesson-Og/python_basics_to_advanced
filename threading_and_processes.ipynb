{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading and Multi processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can run a  code in parallel to speed up operation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Process:A process is an instance of a program (e.g a Python Intepreter or FIREFOX browser)* \n",
    "## *Thread: An entity within a process. A process can have multiple threads*\n",
    "\n",
    "\n",
    "###  Advantages of Processes\n",
    "\n",
    "1) Takes advantage of multiple CPUs and cores\n",
    "\n",
    "\n",
    "2) Separate memory space -> Memory is not shared between processes\n",
    "\n",
    "\n",
    "3) Great for CPU-bound processing\n",
    "\n",
    "\n",
    "4) New process is stated independently from others\n",
    "\n",
    "\n",
    "5) Processes are interuptable / killable\n",
    "\n",
    "\n",
    "6) One GIL (Global Interpreter Lock) for each process -> avoids GIL limitation\n",
    "\n",
    "### Disadvantages of  processes \n",
    "- Heavyweight \n",
    "- Starting a process is a slower process than starting a thread\n",
    "- More memory\n",
    "- IPC (Inter -process communication) is more complicated\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threads: An entity within a process  that can be scheduled(also known as a lightweight process)\n",
    "#### A process can spawn multiple threads\n",
    "\n",
    "#### Advantages of threads\n",
    "1.) All threads within a process share memory\n",
    "\n",
    "\n",
    "2.) Lightweight \n",
    "\n",
    "\n",
    "3.) Starting a thread is faster than starting a process\n",
    "\n",
    "\n",
    "4.) Great for I/O bound processes\n",
    "\n",
    "#### Disadvantages of threads\n",
    "1.) Threading is limited by GIL: Only one thread at a time\n",
    "    \n",
    "    \n",
    "2.) No effect for CPU bound tasks\n",
    "\n",
    "\n",
    "3.) Not interruptable/ killable\n",
    "\n",
    "\n",
    "4.) Careful with race conditions(When two or more threads want to modify the same variable at the same time) bugs or crushes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIL Global Interpreter Lock\n",
    "\n",
    "#### Properties\n",
    "1.) A lock that allows only one thread at a time to execute in Python\n",
    "\n",
    "\n",
    "2.) Needed in CPython because memory management  is not a thread-safe\n",
    "\n",
    "3.) CPython is the referrence Python implementation you get when you download and installPython from Python.org. In CPython \n",
    "there is a memory management that is not thread-safe. So in CPython there is a technique called referrence counting for memory management.\n",
    "\n",
    "\n",
    "\n",
    "This means that objects created in Python have a referrence count variable that keeps track of the number of referrences that point to the object. So when the number reaches zero the memory occupied by this object can be released.\n",
    "\n",
    "\n",
    "\n",
    "The problem is that these variables need protection from threads that can increase or decrease the value simultenously. When this happens it can cause memory leak that has not been released or it can incorrectly release memory when the object still exist.\n",
    "\n",
    "\n",
    "This is the reason they introduced the GIL. you can use a couple of ways to avoid the GIL should you need multi-processing.\n",
    "\n",
    "\n",
    "\n",
    "#### Avoiding GIL:\n",
    "1.)  Use multiprocessing\n",
    "\n",
    "\n",
    "2.)  Use a different, free threaded Python Implementation (Jython, IronPython) instead of CPython.\n",
    "\n",
    "\n",
    "3.) Use Python as a wrapper for third-party libraries (C/C++) -> This is why numpy and scipy can be faster. NumPy, Scipy just use python wrapper while running in those faster languages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "end main\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "def square_numbers():\n",
    "    for i in range(100):\n",
    "        i*i\n",
    "        time.sleep(0.1)\n",
    "processes = []\n",
    "# a good count is the number of cores on your machine\n",
    "\n",
    "num_processors = os.cpu_count()\n",
    "print(num_processors)\n",
    "\n",
    "for i in range(num_processors):\n",
    "    p =Process(target=square_numbers)\n",
    "    processes.append(p)\n",
    "    \n",
    "    \n",
    "# starting a process\n",
    "for p in processes:\n",
    "    p.start()\n",
    "\n",
    "# join processes\n",
    "for p in processes:\n",
    "    p.join()\n",
    "    \n",
    "print('end main')\n",
    "        \n",
    "# the stuff above is to wait for the processes to finish while blocking the main thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threading API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "\n",
    "num_threads = 10\n",
    "threads = []\n",
    "\n",
    "for i in range(num_threads):\n",
    "    t = Thread(target=square_numbers)\n",
    "    threads.append(t)\n",
    "\n",
    "# to start threads\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "# join threads: wait for them to complete by blocking the main thread until the thread is complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since threads live in the same memory space they have access to the same data. This gives them an opportunity to share data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end main\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "database_value = 0\n",
    "def square_numbers():\n",
    "    for i in range(100):\n",
    "        i*i\n",
    "        time.sleep(0.1)\n",
    "threads = []\n",
    "\n",
    "\n",
    "for i in range(num_processors):\n",
    "    t = Thread(target=square_numbers)\n",
    "    threads.append(t)\n",
    "    \n",
    "    \n",
    "# start each threa\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "# join threads: wait for them to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "    \n",
    "print('end main')\n",
    "        \n",
    "# the stuff above is to wait for the processes to finish while blocking the main thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start value 0\n",
      "end value 1\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "\n",
    "# This should simulate a database as we share memory\n",
    "database_value = 0\n",
    "\n",
    "def increase():\n",
    "    global database_value\n",
    "    \n",
    "    local_copy = database_value\n",
    "    \n",
    "    local_copy +=1\n",
    "    # in order to wait a bit 0.1 seconds\n",
    "    '''\n",
    "    The end value is one instead of two because the first thread went on sleep and the second one immediately \n",
    "    started. This was all before the localupdated variable could change database so they all return to database\n",
    "    value with an update of one.\n",
    "    \n",
    "    To prevent this you can use the lock.\n",
    "    '''\n",
    "    time.sleep(0.1)\n",
    "    database_value = local_copy\n",
    "\n",
    "print('Start value', database_value)\n",
    "\n",
    "thread_1 = Thread(target=increase)\n",
    "thread_2 = Thread(target=increase)\n",
    "\n",
    "thread_1.start()\n",
    "thread_2.start()\n",
    "\n",
    "thread_1.join()\n",
    "thread_2.join()\n",
    "\n",
    "print('end value', database_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using a lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start value 0\n",
      "end value 2\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Lock\n",
    "import time\n",
    "\n",
    "\n",
    "# This should simulate a database as we share memory\n",
    "database_value = 0\n",
    "\n",
    "def increase(lock):\n",
    "    global database_value\n",
    "    \n",
    "    with lock:\n",
    "        local_copy = database_value\n",
    "\n",
    "        local_copy +=1\n",
    "        # in order to wait a bit 0.1 seconds\n",
    "        '''\n",
    "        Whenever you use lock.acquire() a lock you should release it below with a lock.release() otherwise it will remain stuck.\n",
    "        The purpose of the lock is to allow the first thread to lock the memory and modify before releasing.\n",
    "\n",
    "        It is however recommended to use with lock (Using lock as a context manager)\n",
    "        '''\n",
    "        time.sleep(0.1)\n",
    "        database_value = local_copy\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "lock = Lock()\n",
    "print('Start value', database_value)\n",
    "\n",
    "thread_1 = Thread(target=increase, args=(lock,))\n",
    "thread_2 = Thread(target=increase, args=(lock,))\n",
    "\n",
    "thread_1.start()\n",
    "thread_2.start()\n",
    "\n",
    "thread_1.join()\n",
    "thread_2.join()\n",
    "\n",
    "print('end value', database_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now moving on to queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Lock\n",
    "import time\n",
    "from queue import Queue\n",
    "#A queue is a linear data structure that follows a FIFO (First in first Out)\n",
    "\n",
    "\n",
    "\n",
    "q = Queue()\n",
    "q.put(1)\n",
    "q.put(2)\n",
    "q.put(3)\n",
    "\n",
    "first =q.get()\n",
    "print(first)\n",
    "# To block the main thread until all the threads are done you use q.join()\n",
    "q.join()\n",
    "\n",
    "\n",
    "# When done with a queue method you invoke q.task_done()\n",
    "q.task_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Thread-16 got 1\n",
      "In Thread-20 got 2\n",
      "In Thread-19 got 3\n",
      "In Thread-21 got 4\n",
      "In Thread-17 got 5\n",
      "In Thread-22 got 6\n",
      "In Thread-18 got 7\n",
      "In Thread-23 got 8\n",
      "In Thread-24 got 9\n",
      "In Thread-25 got 10\n",
      "In Thread-16 got 11\n",
      "In Thread-20 got 12\n",
      "In Thread-19 got 13\n",
      "In Thread-21 got 14\n",
      "In Thread-17 got 15\n",
      "In Thread-22 got 16\n",
      "In Thread-18 got 17\n",
      "In Thread-23 got 18\n",
      "In Thread-24 got 19\n",
      "In Thread-25 got 20\n",
      "end main\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Lock, current_thread\n",
    "import time\n",
    "from queue import Queue\n",
    "\n",
    "\n",
    "def worker(q, lock):\n",
    "    while True:\n",
    "        value = q.get()\n",
    "        \n",
    "        # do some processing\n",
    "        with lock:\n",
    "            print(f'In {current_thread().name} got {value}')\n",
    "        q.task_done()\n",
    "        \n",
    "        \n",
    "        \n",
    "q = Queue()\n",
    "lock = Lock()\n",
    "num_threads = 10\n",
    "\n",
    "for i in range(num_threads):\n",
    "    thread = Thread(target=worker, args =(q, lock))\n",
    "    thread.daemon = True\n",
    "    thread.start()\n",
    "    \n",
    "for i in range(1, 21):\n",
    "    q.put(i)\n",
    "    \n",
    "\n",
    "q.join()\n",
    "print('end main')\n",
    "# A daemon thread is a thread which dies when the main thread dies.\n",
    "#If you do not use a daemon thread then our programme continues in the infinite while True loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
